{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXlQJwf+SiJ9W8YZY+lliw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mamuncseru/learning_transformer/blob/main/Tokens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPsImKOrj2RG",
        "outputId": "275e1901-cdad-401b-d6af-fc9350cc0e33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "  >>> import nltk\n",
        "  >>> nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet = \"\"\"I’m amazed how often in practice, not only does a @huggingface NLP model solve your problem, but one of their public finetuned checkpoints, is good enough for the job.\n",
        "\n",
        "Both impressed, and a little disappointed how rarely I get to actually train a model that matters :(\"\"\""
      ],
      "metadata": {
        "id": "VvnAL9V_j4XF"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* A word\n",
        "* Part of word\n",
        "* A single character\n",
        "* Punctuation makr[,!-,]\n",
        "* Special token <URL>, or <NAME>\n",
        "* Model-specific special tokens, like [CLS] and [SEP] for BERT\n"
      ],
      "metadata": {
        "id": "5z5bS7SLj8Q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[char for char in tweet]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz95QSKjj7yL",
        "outputId": "0e6c6ef9-7f2e-47f3-b772-7f9593bb74a6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " '’',\n",
              " 'm',\n",
              " ' ',\n",
              " 'a',\n",
              " 'm',\n",
              " 'a',\n",
              " 'z',\n",
              " 'e',\n",
              " 'd',\n",
              " ' ',\n",
              " 'h',\n",
              " 'o',\n",
              " 'w',\n",
              " ' ',\n",
              " 'o',\n",
              " 'f',\n",
              " 't',\n",
              " 'e',\n",
              " 'n',\n",
              " ' ',\n",
              " 'i',\n",
              " 'n',\n",
              " ' ',\n",
              " 'p',\n",
              " 'r',\n",
              " 'a',\n",
              " 'c',\n",
              " 't',\n",
              " 'i',\n",
              " 'c',\n",
              " 'e',\n",
              " ',',\n",
              " ' ',\n",
              " 'n',\n",
              " 'o',\n",
              " 't',\n",
              " ' ',\n",
              " 'o',\n",
              " 'n',\n",
              " 'l',\n",
              " 'y',\n",
              " ' ',\n",
              " 'd',\n",
              " 'o',\n",
              " 'e',\n",
              " 's',\n",
              " ' ',\n",
              " 'a',\n",
              " ' ',\n",
              " '@',\n",
              " 'h',\n",
              " 'u',\n",
              " 'g',\n",
              " 'g',\n",
              " 'i',\n",
              " 'n',\n",
              " 'g',\n",
              " 'f',\n",
              " 'a',\n",
              " 'c',\n",
              " 'e',\n",
              " ' ',\n",
              " 'N',\n",
              " 'L',\n",
              " 'P',\n",
              " ' ',\n",
              " 'm',\n",
              " 'o',\n",
              " 'd',\n",
              " 'e',\n",
              " 'l',\n",
              " ' ',\n",
              " 's',\n",
              " 'o',\n",
              " 'l',\n",
              " 'v',\n",
              " 'e',\n",
              " ' ',\n",
              " 'y',\n",
              " 'o',\n",
              " 'u',\n",
              " 'r',\n",
              " ' ',\n",
              " 'p',\n",
              " 'r',\n",
              " 'o',\n",
              " 'b',\n",
              " 'l',\n",
              " 'e',\n",
              " 'm',\n",
              " ',',\n",
              " ' ',\n",
              " 'b',\n",
              " 'u',\n",
              " 't',\n",
              " ' ',\n",
              " 'o',\n",
              " 'n',\n",
              " 'e',\n",
              " ' ',\n",
              " 'o',\n",
              " 'f',\n",
              " ' ',\n",
              " 't',\n",
              " 'h',\n",
              " 'e',\n",
              " 'i',\n",
              " 'r',\n",
              " ' ',\n",
              " 'p',\n",
              " 'u',\n",
              " 'b',\n",
              " 'l',\n",
              " 'i',\n",
              " 'c',\n",
              " ' ',\n",
              " 'f',\n",
              " 'i',\n",
              " 'n',\n",
              " 'e',\n",
              " 't',\n",
              " 'u',\n",
              " 'n',\n",
              " 'e',\n",
              " 'd',\n",
              " ' ',\n",
              " 'c',\n",
              " 'h',\n",
              " 'e',\n",
              " 'c',\n",
              " 'k',\n",
              " 'p',\n",
              " 'o',\n",
              " 'i',\n",
              " 'n',\n",
              " 't',\n",
              " 's',\n",
              " ',',\n",
              " ' ',\n",
              " 'i',\n",
              " 's',\n",
              " ' ',\n",
              " 'g',\n",
              " 'o',\n",
              " 'o',\n",
              " 'd',\n",
              " ' ',\n",
              " 'e',\n",
              " 'n',\n",
              " 'o',\n",
              " 'u',\n",
              " 'g',\n",
              " 'h',\n",
              " ' ',\n",
              " 'f',\n",
              " 'o',\n",
              " 'r',\n",
              " ' ',\n",
              " 't',\n",
              " 'h',\n",
              " 'e',\n",
              " ' ',\n",
              " 'j',\n",
              " 'o',\n",
              " 'b',\n",
              " '.',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'B',\n",
              " 'o',\n",
              " 't',\n",
              " 'h',\n",
              " ' ',\n",
              " 'i',\n",
              " 'm',\n",
              " 'p',\n",
              " 'r',\n",
              " 'e',\n",
              " 's',\n",
              " 's',\n",
              " 'e',\n",
              " 'd',\n",
              " ',',\n",
              " ' ',\n",
              " 'a',\n",
              " 'n',\n",
              " 'd',\n",
              " ' ',\n",
              " 'a',\n",
              " ' ',\n",
              " 'l',\n",
              " 'i',\n",
              " 't',\n",
              " 't',\n",
              " 'l',\n",
              " 'e',\n",
              " ' ',\n",
              " 'd',\n",
              " 'i',\n",
              " 's',\n",
              " 'a',\n",
              " 'p',\n",
              " 'p',\n",
              " 'o',\n",
              " 'i',\n",
              " 'n',\n",
              " 't',\n",
              " 'e',\n",
              " 'd',\n",
              " ' ',\n",
              " 'h',\n",
              " 'o',\n",
              " 'w',\n",
              " ' ',\n",
              " 'r',\n",
              " 'a',\n",
              " 'r',\n",
              " 'e',\n",
              " 'l',\n",
              " 'y',\n",
              " ' ',\n",
              " 'I',\n",
              " ' ',\n",
              " 'g',\n",
              " 'e',\n",
              " 't',\n",
              " ' ',\n",
              " 't',\n",
              " 'o',\n",
              " ' ',\n",
              " 'a',\n",
              " 'c',\n",
              " 't',\n",
              " 'u',\n",
              " 'a',\n",
              " 'l',\n",
              " 'l',\n",
              " 'y',\n",
              " ' ',\n",
              " 't',\n",
              " 'r',\n",
              " 'a',\n",
              " 'i',\n",
              " 'n',\n",
              " ' ',\n",
              " 'a',\n",
              " ' ',\n",
              " 'm',\n",
              " 'o',\n",
              " 'd',\n",
              " 'e',\n",
              " 'l',\n",
              " ' ',\n",
              " 't',\n",
              " 'h',\n",
              " 'a',\n",
              " 't',\n",
              " ' ',\n",
              " 'm',\n",
              " 'a',\n",
              " 't',\n",
              " 't',\n",
              " 'e',\n",
              " 'r',\n",
              " 's',\n",
              " ' ',\n",
              " ':',\n",
              " '(']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "@elonmusk thinks that the NLP models that @joebloggs made are super cool\n",
        "\n",
        "@joebloggs thinks that the NLP models that @huggingface made are super cool\n",
        "\n",
        "<USER> thinks that the NLP models that <USER> made super cool"
      ],
      "metadata": {
        "id": "HsZcH_zVlEd5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Special Model Tokens"
      ],
      "metadata": {
        "id": "ReBU3vB9kfAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Token\tMeaning\n",
        "\n",
        "[PAD]\tPadding token, allows us to maintain same-length sequences (512 tokens for Bert) even when different sized sentences are fed in\n",
        "\n",
        "[UNK]\tUsed when a word is unknown to Bert\n",
        "\n",
        "[CLS]\tAppears at the start of every sequence\n",
        "\n",
        "[SEP]\tIndicates a seperator or end of sequence\n",
        "\n",
        "[MASK]\tUsed when masking tokens, for example in training with masked language modelling (MLM)"
      ],
      "metadata": {
        "id": "EIDPh-C4lucK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LL5RxdK7lqL8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}